version: '3.8'

# ==============================================================
# SECURITY AUTOMATION PLATFORM - PLUGGABLE CONFIGURATION
# ==============================================================
# This setup allows you to scan ANY application by mounting
# its directory into the correlation-engine container.
#
# Usage:
#   1. Set TARGET_APP_PATH environment variable to your app's directory
#   2. Run: docker-compose up -d
#   3. Scan via API or CLI
#
# Example:
#   TARGET_APP_PATH=./my-java-app docker-compose up -d
#   curl -X POST http://localhost:8000/api/scan -d '{"path": "/target-app"}'
# ==============================================================

services:
  # Ollama LLM for AI-powered patch generation
  ollama:
    image: ollama/ollama:latest
    container_name: security-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama
    networks:
      - security-automation-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 12G
        reservations:
          memory: 8G

  # Security Automation Platform (Correlation Engine)
  correlation-engine:
    build:
      context: .
      dockerfile: Dockerfile
    image: security-automation-platform:latest
    container_name: security-correlation
    ports:
      - "8000:8000"
    volumes:
      # Mount YOUR application directory here
      # Change TARGET_APP_PATH to point to your application
      - ${TARGET_APP_PATH:-.}:/target-app:ro
      # Persist scan results, patches, and CodeQL databases
      - correlation-data:/data
      - ./test-data:/app/test-data
      - codeql-databases:/data/codeql-databases
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-deepseek-coder:6.7b-instruct}
      - DATABASE_URL=sqlite:////data/security.db
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - TARGET_APP_PATH=/target-app
      - CODEQL_HOME=/opt/codeql
      - CODEQL_QUERIES=/opt/codeql-repo
    networks:
      - security-automation-network
    depends_on:
      ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    command: >
      sh -c "
        echo '🚀 Security Automation Platform Starting...'
        echo '📁 Target Application: /target-app'
        echo '🤖 LLM Provider: ${LLM_PROVIDER:-ollama}'
        echo '🔍 CodeQL Home: /opt/codeql'
        echo ''
        echo '✅ Platform Ready!'
        echo ''
        echo '🌐 API Endpoints:'
        echo '  - Status: http://localhost:8000/api/v1/status'
        echo '  - E2E Analysis: POST http://localhost:8000/api/v1/e2e/analyze-and-fix'
        echo '  - Semantic Analysis: POST http://localhost:8000/api/v1/semantic/analyze'
        echo '  - Generate Patches: POST http://localhost:8000/api/v1/vulnerabilities/{id}/generate-patch'
        echo '  - Dashboard: GET http://localhost:8000/api/v1/dashboard'
        echo ''
        echo '🔧 CLI Usage (inside container):'
        echo '  docker exec security-correlation python api_client.py'
        echo ''
        echo '📚 Documentation: http://localhost:8000/docs (Swagger UI)'
        echo ''
        uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
      "

volumes:
  ollama-models:
    name: security-ollama-models
  correlation-data:
    name: security-correlation-data
  codeql-databases:
    name: security-codeql-databases

networks:
  security-automation-network:
    name: security-automation-network
    driver: bridge
